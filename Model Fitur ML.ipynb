{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn tensorflow numpy matplotlib seaborn pydrive Sastrawi simpletransformers"
      ],
      "metadata": {
        "id": "Rv1dmgl1WWWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from simpletransformers.language_representation import RepresentationModel\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D"
      ],
      "metadata": {
        "id": "S9e0Slu8aSyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "EMLrhnwutzAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat variabel untuk dataset\n",
        "nama_file = 'dataset_pembullyan.csv'\n",
        "\n",
        "# Membaca dataset\n",
        "dataset = pd.read_csv(nama_file)"
      ],
      "metadata": {
        "id": "Kq7nA1YTGsjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "05rWT9vsGxqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(10)"
      ],
      "metadata": {
        "id": "S5fin0e8G1bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memisahkan dataset berdasarkan nilai pada kolom 'class'\n",
        "grouped_datasets = dict(tuple(dataset.groupby('class')))\n",
        "\n",
        "# Menampilkan isi dari setiap subdataset\n",
        "for class_value, subdataset in grouped_datasets.items():\n",
        "    print(f\"\\nClass: {class_value}\")\n",
        "    print(subdataset)"
      ],
      "metadata": {
        "id": "qg5A1cD7muVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan banyak dari kolom kelas dengan seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='class', data=dataset, palette='pastel')  # Gunakan palet warna 'pastel' untuk tampilan yang lembut\n",
        "plt.title('Banyak Data untuk Setiap Type Kekerasan')\n",
        "plt.xlabel('Tingkat Kekerasan')\n",
        "plt.ylabel('Jumlah')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HPRTMKbevpq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca dataset kata-kata\n",
        "kata_kata_file_path = 'dataset_pembullyan.csv'\n",
        "kata_kata_dataset = pd.read_csv(kata_kata_file_path)\n",
        "\n",
        "# Membaca dataset user\n",
        "user_file_path = 'dataset_user.csv'\n",
        "user_dataset = pd.read_csv(user_file_path)\n",
        "\n",
        "# Pemisahan dataset menjadi set pelatihan dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    kata_kata_dataset['text'], kata_kata_dataset['class'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Menggunakan TF-IDF untuk mengubah teks menjadi vektor fitur\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Konversi label kategori menjadi angka\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Membangun model deep learning\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(vectorizer.get_feature_names_out()), output_dim=16, input_length=X_train_tfidf.shape[1]))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))  # 3 karena terdapat 3 kategori: rendah, sedang, parah\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Melatih model\n",
        "model.fit(X_train_tfidf.toarray(), y_train_encoded, epochs=1000, validation_data=(X_test_tfidf.toarray(), y_test_encoded))\n",
        "\n",
        "# Melakukan prediksi pada set pengujian\n",
        "y_pred_probs = model.predict(X_test_tfidf.toarray())\n",
        "y_pred = y_pred_probs.argmax(axis=1)\n",
        "\n",
        "# Evaluasi performa model\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "classification_report_result = classification_report(y_test_encoded, y_pred, target_names=label_encoder.classes_)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print('Classification Report:')\n",
        "print(classification_report_result)\n"
      ],
      "metadata": {
        "id": "eItXKz0MRBgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan model untuk prediksi pada kalimat user\n",
        "user_tfidf = vectorizer.transform(user_dataset['kalimat'])\n",
        "user_predictions_probs = model.predict(user_tfidf.toarray())\n",
        "user_predictions = user_predictions_probs.argmax(axis=1)\n",
        "user_dataset['Predicted_Class'] = label_encoder.inverse_transform(user_predictions)\n",
        "\n",
        "print('\\nHasil untuk Kalimat User:')\n",
        "print(user_dataset[['kalimat', 'Predicted_Class']])"
      ],
      "metadata": {
        "id": "lQve4oN7h2sZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}